{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "755d75cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 0. Setup Data Paths\n",
    "nhanes_step_count_dir = \"./data/nhanes-step-count/\"\n",
    "subject_info_path = os.path.join(nhanes_step_count_dir, \"subject-info.csv\")\n",
    "actisteps_path = os.path.join(nhanes_step_count_dir, \"nhanes_1440_actisteps.csv.xz\")\n",
    "ac_path = os.path.join(nhanes_step_count_dir, \"nhanes_1440_AC.csv.xz\")\n",
    "mims_path = os.path.join(nhanes_step_count_dir, \"nhanes_1440_PAXMTSM.csv.xz\")\n",
    "\n",
    "nhanes_lab_dir = \"./data/nhanes-lab/\"\n",
    "ghb_path_2011 = os.path.join(nhanes_lab_dir, \"ghb-2011-12.xpt\")\n",
    "ghb_path_2013 = os.path.join(nhanes_lab_dir, \"ghb-2013-14.xpt\")\n",
    "\n",
    "nhanes_questionnaire_dir = \"./data/nhanes-questionnaire/\"\n",
    "bpq_path_2011 = os.path.join(nhanes_questionnaire_dir, \"bpq-2011-12.xpt\")\n",
    "bpq_path_2013 = os.path.join(nhanes_questionnaire_dir, \"bpq-2013-14.xpt\")\n",
    "\n",
    "nhanes_exam_dir = \"./data/nhanes-examination/\"\n",
    "bmx_path_2011 = os.path.join(nhanes_exam_dir, \"bmx-2011-12.xpt\")\n",
    "bmx_path_2013 = os.path.join(nhanes_exam_dir, \"bmx-2013-14.xpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "acd48cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Wearable Movement Data... (this may take a few minutes)\n",
      "Wearable Data Shape:\n",
      "- Subject Info: (19931, 8)\n",
      "- Activity Counts: (130186, 1443)\n",
      "- MIMS: (130186, 1443)\n",
      "Wearable Data Shape:\n",
      "- Subject Info: (19931, 8)\n",
      "- Activity Counts: (130186, 1443)\n",
      "- MIMS: (130186, 1443)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Load NHANES Step-Count Data\n",
    "print(\"Loading Wearable Movement Data... (this may take a few minutes)\")\n",
    "\n",
    "subj_df = pd.read_csv(subject_info_path, dtype={\"SEQN\": \"Int64\"})\n",
    "ac_df = pd.read_csv(ac_path, dtype={\"SEQN\": \"Int64\"}, low_memory=False)\n",
    "mims_df = pd.read_csv(mims_path, dtype={\"SEQN\": \"Int64\"}, low_memory=False)\n",
    "\n",
    "print(\"Wearable Data Shape:\")\n",
    "print(\"- Subject Info:\", subj_df.shape)\n",
    "print(\"- Activity Counts:\", ac_df.shape)\n",
    "print(\"- MIMS:\", mims_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "ef7a5dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Wearable Data Features...\n",
      "Computed MIMS Intensity Thresholds:\n",
      "Sedentary: MIMS > 0 and < 1.0\n",
      "Vigorous: MIMS > 36.9\n",
      "Computed MIMS Intensity Thresholds:\n",
      "Sedentary: MIMS > 0 and < 1.0\n",
      "Vigorous: MIMS > 36.9\n",
      "['SEQN', 'data_release_cycle', 'gender', 'age_in_years_at_screening', 'full_sample_2_year_interview_weight', 'full_sample_2_year_mec_exam_weight', 'masked_variance_pseudo_psu', 'masked_variance_pseudo_stratum']\n",
      "\n",
      "--- Intensity Feature Summary ---\n",
      "Mean sedentary mins/day: 234.7\n",
      "Mean vigorous mins/day: 47.0\n",
      "['SEQN', 'data_release_cycle', 'gender', 'age_in_years_at_screening', 'full_sample_2_year_interview_weight', 'full_sample_2_year_mec_exam_weight', 'masked_variance_pseudo_psu', 'masked_variance_pseudo_stratum']\n",
      "\n",
      "--- Intensity Feature Summary ---\n",
      "Mean sedentary mins/day: 234.7\n",
      "Mean vigorous mins/day: 47.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEQN</th>\n",
       "      <th>mean_daily_AC</th>\n",
       "      <th>sd_daily_AC</th>\n",
       "      <th>mean_sedentary_mins</th>\n",
       "      <th>mean_vigorous_mins</th>\n",
       "      <th>age_in_years_at_screening</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>14693.0</td>\n",
       "      <td>1.469300e+04</td>\n",
       "      <td>1.469300e+04</td>\n",
       "      <td>14693.000000</td>\n",
       "      <td>14693.000000</td>\n",
       "      <td>14693.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>73182.610223</td>\n",
       "      <td>2.149897e+06</td>\n",
       "      <td>1.062692e+06</td>\n",
       "      <td>234.660112</td>\n",
       "      <td>47.042718</td>\n",
       "      <td>35.750561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6486.170446</td>\n",
       "      <td>8.845152e+05</td>\n",
       "      <td>4.441004e+05</td>\n",
       "      <td>201.927361</td>\n",
       "      <td>45.543309</td>\n",
       "      <td>23.182327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>62161.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>67312.0</td>\n",
       "      <td>1.570828e+06</td>\n",
       "      <td>7.569292e+05</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>12.333333</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>74099.0</td>\n",
       "      <td>2.129073e+06</td>\n",
       "      <td>1.028766e+06</td>\n",
       "      <td>144.888889</td>\n",
       "      <td>32.500000</td>\n",
       "      <td>33.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>78969.0</td>\n",
       "      <td>2.733879e+06</td>\n",
       "      <td>1.333697e+06</td>\n",
       "      <td>333.666667</td>\n",
       "      <td>68.888889</td>\n",
       "      <td>55.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>83731.0</td>\n",
       "      <td>7.206275e+06</td>\n",
       "      <td>7.410255e+06</td>\n",
       "      <td>1280.888889</td>\n",
       "      <td>409.444444</td>\n",
       "      <td>80.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               SEQN  mean_daily_AC   sd_daily_AC  mean_sedentary_mins  \\\n",
       "count       14693.0   1.469300e+04  1.469300e+04         14693.000000   \n",
       "mean   73182.610223   2.149897e+06  1.062692e+06           234.660112   \n",
       "std     6486.170446   8.845152e+05  4.441004e+05           201.927361   \n",
       "min         62161.0   0.000000e+00  0.000000e+00             0.000000   \n",
       "25%         67312.0   1.570828e+06  7.569292e+05            99.000000   \n",
       "50%         74099.0   2.129073e+06  1.028766e+06           144.888889   \n",
       "75%         78969.0   2.733879e+06  1.333697e+06           333.666667   \n",
       "max         83731.0   7.206275e+06  7.410255e+06          1280.888889   \n",
       "\n",
       "       mean_vigorous_mins  age_in_years_at_screening  \n",
       "count        14693.000000               14693.000000  \n",
       "mean            47.042718                  35.750561  \n",
       "std             45.543309                  23.182327  \n",
       "min              0.000000                   3.000000  \n",
       "25%             12.333333                  14.000000  \n",
       "50%             32.500000                  33.000000  \n",
       "75%             68.888889                  55.000000  \n",
       "max            409.444444                  80.000000  "
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 2. Feature Engineering for NHANES Step-Count Data\n",
    "print(\"Computing Wearable Data Features...\")\n",
    "\n",
    "# Compute Activity Counts Features\n",
    "ac_minute_cols = [c for c in ac_df.columns if c.startswith(\"min_\")]\n",
    "ac_df[\"daily_AC\"] = ac_df[ac_minute_cols].sum(axis=1, numeric_only=True)\n",
    "ac_agg = ac_df.groupby(\"SEQN\").agg(\n",
    "    mean_daily_AC=(\"daily_AC\", \"mean\"),\n",
    "    sd_daily_AC=(\"daily_AC\", \"std\")\n",
    ").reset_index()\n",
    "ac_agg[\"sd_daily_AC\"] = ac_agg[\"sd_daily_AC\"].fillna(0.0)\n",
    "\n",
    "selected_columns = [\"SEQN\", \"mean_daily_AC\", \"sd_daily_AC\"]\n",
    "df = ac_agg[selected_columns].copy()\n",
    "\n",
    "# Compute MIMS Activity Intensity Bins\n",
    "mims_minute_cols = [c for c in mims_df.columns if c.startswith(\"min_\")]\n",
    "mims_values = mims_df[mims_minute_cols].values.flatten()\n",
    "mims_values_nonzero = mims_values[mims_values > 0]  # Exclude invalid data (zeros)\n",
    "\n",
    "p25 = np.percentile(mims_values_nonzero, 25)\n",
    "p95 = np.percentile(mims_values_nonzero, 95)\n",
    "\n",
    "print(f\"Computed MIMS Intensity Thresholds:\")\n",
    "print(f\"Sedentary: MIMS > 0 and < {p25:.1f}\")\n",
    "print(f\"Vigorous: MIMS > {p95:.1f}\")\n",
    "\n",
    "mims_vals = mims_df[mims_minute_cols].values\n",
    "sedentary_mins = ((mims_vals > 0) & (mims_vals < p25)).sum(axis=1)\n",
    "vigorous_mins = (mims_vals >= p95).sum(axis=1)\n",
    "mims_df[\"sedentary_mins\"] = sedentary_mins\n",
    "mims_df[\"vigorous_mins\"] = vigorous_mins\n",
    "\n",
    "mims_agg = mims_df.groupby(\"SEQN\").agg(\n",
    "    mean_sedentary_mins=(\"sedentary_mins\", \"mean\"),\n",
    "    mean_vigorous_mins=(\"vigorous_mins\", \"mean\"),\n",
    ").reset_index()\n",
    "\n",
    "df = df.merge(mims_agg, on=\"SEQN\", how=\"left\")\n",
    "\n",
    "# Merge with Subject Info\n",
    "print(subj_df.columns.tolist())\n",
    "selected_columns = [\"SEQN\", \"age_in_years_at_screening\"]\n",
    "subj_df = subj_df[selected_columns].copy()\n",
    "df = df.merge(subj_df, on=\"SEQN\", how=\"left\")\n",
    "\n",
    "print(\"\\n--- Intensity Feature Summary ---\")\n",
    "print(f\"Mean sedentary mins/day: {df['mean_sedentary_mins'].mean():.1f}\")\n",
    "print(f\"Mean vigorous mins/day: {df['mean_vigorous_mins'].mean():.1f}\")\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "41ce0c34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEQN</th>\n",
       "      <th>mean_daily_AC</th>\n",
       "      <th>sd_daily_AC</th>\n",
       "      <th>mean_sedentary_mins</th>\n",
       "      <th>mean_vigorous_mins</th>\n",
       "      <th>age_in_years_at_screening</th>\n",
       "      <th>high_blood_pressure</th>\n",
       "      <th>high_cholesterol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10095.0</td>\n",
       "      <td>1.009500e+04</td>\n",
       "      <td>1.009500e+04</td>\n",
       "      <td>10095.000000</td>\n",
       "      <td>10095.000000</td>\n",
       "      <td>10095.000000</td>\n",
       "      <td>10095.000000</td>\n",
       "      <td>10095.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>73319.500446</td>\n",
       "      <td>1.954497e+06</td>\n",
       "      <td>9.575282e+05</td>\n",
       "      <td>238.171978</td>\n",
       "      <td>29.857635</td>\n",
       "      <td>47.330758</td>\n",
       "      <td>1.652402</td>\n",
       "      <td>1.715206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6475.933328</td>\n",
       "      <td>7.722925e+05</td>\n",
       "      <td>4.016700e+05</td>\n",
       "      <td>196.574201</td>\n",
       "      <td>31.715496</td>\n",
       "      <td>18.599095</td>\n",
       "      <td>0.526048</td>\n",
       "      <td>0.743788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>62161.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>67473.5</td>\n",
       "      <td>1.469515e+06</td>\n",
       "      <td>6.871479e+05</td>\n",
       "      <td>106.333333</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>74262.0</td>\n",
       "      <td>1.944626e+06</td>\n",
       "      <td>9.244403e+05</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>20.777778</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>79129.0</td>\n",
       "      <td>2.448072e+06</td>\n",
       "      <td>1.188741e+06</td>\n",
       "      <td>320.277778</td>\n",
       "      <td>41.333333</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>83729.0</td>\n",
       "      <td>6.911811e+06</td>\n",
       "      <td>5.098803e+06</td>\n",
       "      <td>1280.888889</td>\n",
       "      <td>343.666667</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               SEQN  mean_daily_AC   sd_daily_AC  mean_sedentary_mins  \\\n",
       "count       10095.0   1.009500e+04  1.009500e+04         10095.000000   \n",
       "mean   73319.500446   1.954497e+06  9.575282e+05           238.171978   \n",
       "std     6475.933328   7.722925e+05  4.016700e+05           196.574201   \n",
       "min         62161.0   0.000000e+00  0.000000e+00             0.000000   \n",
       "25%         67473.5   1.469515e+06  6.871479e+05           106.333333   \n",
       "50%         74262.0   1.944626e+06  9.244403e+05           155.000000   \n",
       "75%         79129.0   2.448072e+06  1.188741e+06           320.277778   \n",
       "max         83729.0   6.911811e+06  5.098803e+06          1280.888889   \n",
       "\n",
       "       mean_vigorous_mins  age_in_years_at_screening  high_blood_pressure  \\\n",
       "count        10095.000000               10095.000000         10095.000000   \n",
       "mean            29.857635                  47.330758             1.652402   \n",
       "std             31.715496                  18.599095             0.526048   \n",
       "min              0.000000                  16.000000             1.000000   \n",
       "25%              8.000000                  31.000000             1.000000   \n",
       "50%             20.777778                  47.000000             2.000000   \n",
       "75%             41.333333                  62.000000             2.000000   \n",
       "max            343.666667                  80.000000             9.000000   \n",
       "\n",
       "       high_cholesterol  \n",
       "count      10095.000000  \n",
       "mean           1.715206  \n",
       "std            0.743788  \n",
       "min            1.000000  \n",
       "25%            1.000000  \n",
       "50%            2.000000  \n",
       "75%            2.000000  \n",
       "max            9.000000  "
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Load NHANES Questionnaire Data + Merge Features\n",
    "\n",
    "bpq_2011 = pd.read_sas(bpq_path_2011, format=\"xport\")\n",
    "bpq_2013 = pd.read_sas(bpq_path_2013, format=\"xport\")\n",
    "\n",
    "bpq = pd.concat([bpq_2011, bpq_2013], ignore_index=True)\n",
    "# BPQ020: Ever told you had high blood pressure\n",
    "# BPQ080: Doctor told you - high cholesterol level\n",
    "selected_columns = [\"SEQN\", \"BPQ020\", \"BPQ080\"]\n",
    "bpq = bpq[selected_columns].copy()\n",
    "bpq = bpq.dropna()\n",
    "bpq = bpq.rename(columns={'BPQ020': 'high_blood_pressure', 'BPQ080': 'high_cholesterol'})\n",
    "\n",
    "df = df.merge(bpq, on=\"SEQN\", how=\"inner\")\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "dae275ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEQN</th>\n",
       "      <th>mean_daily_AC</th>\n",
       "      <th>sd_daily_AC</th>\n",
       "      <th>mean_sedentary_mins</th>\n",
       "      <th>mean_vigorous_mins</th>\n",
       "      <th>age_in_years_at_screening</th>\n",
       "      <th>high_blood_pressure</th>\n",
       "      <th>high_cholesterol</th>\n",
       "      <th>body_mass_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9986.0</td>\n",
       "      <td>9.986000e+03</td>\n",
       "      <td>9.986000e+03</td>\n",
       "      <td>9986.000000</td>\n",
       "      <td>9986.000000</td>\n",
       "      <td>9986.000000</td>\n",
       "      <td>9986.000000</td>\n",
       "      <td>9986.000000</td>\n",
       "      <td>9986.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>73326.487182</td>\n",
       "      <td>1.961222e+06</td>\n",
       "      <td>9.608548e+05</td>\n",
       "      <td>237.289370</td>\n",
       "      <td>30.050645</td>\n",
       "      <td>47.243040</td>\n",
       "      <td>1.654516</td>\n",
       "      <td>1.715301</td>\n",
       "      <td>28.883968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6472.182502</td>\n",
       "      <td>7.699247e+05</td>\n",
       "      <td>4.004607e+05</td>\n",
       "      <td>196.024759</td>\n",
       "      <td>31.776733</td>\n",
       "      <td>18.545804</td>\n",
       "      <td>0.525950</td>\n",
       "      <td>0.742555</td>\n",
       "      <td>7.096445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>62161.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>67483.75</td>\n",
       "      <td>1.477547e+06</td>\n",
       "      <td>6.903926e+05</td>\n",
       "      <td>106.222222</td>\n",
       "      <td>8.111111</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>23.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>74271.5</td>\n",
       "      <td>1.949789e+06</td>\n",
       "      <td>9.261417e+05</td>\n",
       "      <td>154.444444</td>\n",
       "      <td>20.888889</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>27.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>79127.75</td>\n",
       "      <td>2.450939e+06</td>\n",
       "      <td>1.190196e+06</td>\n",
       "      <td>316.666667</td>\n",
       "      <td>41.555556</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>32.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>83729.0</td>\n",
       "      <td>6.911811e+06</td>\n",
       "      <td>5.098803e+06</td>\n",
       "      <td>1280.888889</td>\n",
       "      <td>343.666667</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>82.900000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               SEQN  mean_daily_AC   sd_daily_AC  mean_sedentary_mins  \\\n",
       "count        9986.0   9.986000e+03  9.986000e+03          9986.000000   \n",
       "mean   73326.487182   1.961222e+06  9.608548e+05           237.289370   \n",
       "std     6472.182502   7.699247e+05  4.004607e+05           196.024759   \n",
       "min         62161.0   0.000000e+00  0.000000e+00             0.000000   \n",
       "25%        67483.75   1.477547e+06  6.903926e+05           106.222222   \n",
       "50%         74271.5   1.949789e+06  9.261417e+05           154.444444   \n",
       "75%        79127.75   2.450939e+06  1.190196e+06           316.666667   \n",
       "max         83729.0   6.911811e+06  5.098803e+06          1280.888889   \n",
       "\n",
       "       mean_vigorous_mins  age_in_years_at_screening  high_blood_pressure  \\\n",
       "count         9986.000000                9986.000000          9986.000000   \n",
       "mean            30.050645                  47.243040             1.654516   \n",
       "std             31.776733                  18.545804             0.525950   \n",
       "min              0.000000                  16.000000             1.000000   \n",
       "25%              8.111111                  31.000000             1.000000   \n",
       "50%             20.888889                  47.000000             2.000000   \n",
       "75%             41.555556                  62.000000             2.000000   \n",
       "max            343.666667                  80.000000             9.000000   \n",
       "\n",
       "       high_cholesterol  body_mass_index  \n",
       "count       9986.000000      9986.000000  \n",
       "mean           1.715301        28.883968  \n",
       "std            0.742555         7.096445  \n",
       "min            1.000000        13.600000  \n",
       "25%            1.000000        23.900000  \n",
       "50%            2.000000        27.700000  \n",
       "75%            2.000000        32.400000  \n",
       "max            9.000000        82.900000  "
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. Load NHANES Exammination Data + Merge Features\n",
    "\n",
    "bmx_2011 = pd.read_sas(bmx_path_2011, format=\"xport\")\n",
    "bmx_2013 = pd.read_sas(bmx_path_2013, format=\"xport\")\n",
    "\n",
    "bmx = pd.concat([bmx_2011, bmx_2013], ignore_index=True)\n",
    "# BMXBMI: Body Mass Index (BMI)\n",
    "selected_columns = [\"SEQN\", \"BMXBMI\"]\n",
    "bmx = bmx[selected_columns].copy()\n",
    "bmx = bmx.dropna()\n",
    "bmx = bmx.rename(columns={'BMXBMI': 'body_mass_index'})\n",
    "\n",
    "df = df.merge(bmx, on=\"SEQN\", how=\"inner\")\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "002b3895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Lab A1C Data...\n",
      "Lab Data Shape:\n",
      "- GHB 2011-2012: (6549, 2)\n",
      "- GHB 2013-2014: (6979, 2)\n",
      "Calculating ground truth with A1C lab data...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEQN</th>\n",
       "      <th>mean_daily_AC</th>\n",
       "      <th>sd_daily_AC</th>\n",
       "      <th>mean_sedentary_mins</th>\n",
       "      <th>mean_vigorous_mins</th>\n",
       "      <th>age_in_years_at_screening</th>\n",
       "      <th>high_blood_pressure</th>\n",
       "      <th>high_cholesterol</th>\n",
       "      <th>body_mass_index</th>\n",
       "      <th>diabetes_binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9602.0</td>\n",
       "      <td>9.602000e+03</td>\n",
       "      <td>9.602000e+03</td>\n",
       "      <td>9602.000000</td>\n",
       "      <td>9602.000000</td>\n",
       "      <td>9602.000000</td>\n",
       "      <td>9602.000000</td>\n",
       "      <td>9602.000000</td>\n",
       "      <td>9602.000000</td>\n",
       "      <td>9602.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>73348.953968</td>\n",
       "      <td>1.969803e+06</td>\n",
       "      <td>9.634957e+05</td>\n",
       "      <td>235.599018</td>\n",
       "      <td>30.211757</td>\n",
       "      <td>47.321391</td>\n",
       "      <td>1.654030</td>\n",
       "      <td>1.712768</td>\n",
       "      <td>28.924724</td>\n",
       "      <td>0.374714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6470.569666</td>\n",
       "      <td>7.650447e+05</td>\n",
       "      <td>3.988143e+05</td>\n",
       "      <td>193.667865</td>\n",
       "      <td>31.791210</td>\n",
       "      <td>18.465162</td>\n",
       "      <td>0.528008</td>\n",
       "      <td>0.740866</td>\n",
       "      <td>7.103111</td>\n",
       "      <td>0.484074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>62161.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>67495.25</td>\n",
       "      <td>1.489267e+06</td>\n",
       "      <td>6.947775e+05</td>\n",
       "      <td>106.111111</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>23.900000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>74304.5</td>\n",
       "      <td>1.957202e+06</td>\n",
       "      <td>9.285080e+05</td>\n",
       "      <td>153.555556</td>\n",
       "      <td>21.111111</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>27.700000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>79137.75</td>\n",
       "      <td>2.454120e+06</td>\n",
       "      <td>1.190196e+06</td>\n",
       "      <td>311.944444</td>\n",
       "      <td>41.666667</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>32.400000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>83729.0</td>\n",
       "      <td>6.911811e+06</td>\n",
       "      <td>5.098803e+06</td>\n",
       "      <td>1280.888889</td>\n",
       "      <td>343.666667</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>82.900000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               SEQN  mean_daily_AC   sd_daily_AC  mean_sedentary_mins  \\\n",
       "count        9602.0   9.602000e+03  9.602000e+03          9602.000000   \n",
       "mean   73348.953968   1.969803e+06  9.634957e+05           235.599018   \n",
       "std     6470.569666   7.650447e+05  3.988143e+05           193.667865   \n",
       "min         62161.0   0.000000e+00  0.000000e+00             0.000000   \n",
       "25%        67495.25   1.489267e+06  6.947775e+05           106.111111   \n",
       "50%         74304.5   1.957202e+06  9.285080e+05           153.555556   \n",
       "75%        79137.75   2.454120e+06  1.190196e+06           311.944444   \n",
       "max         83729.0   6.911811e+06  5.098803e+06          1280.888889   \n",
       "\n",
       "       mean_vigorous_mins  age_in_years_at_screening  high_blood_pressure  \\\n",
       "count         9602.000000                9602.000000          9602.000000   \n",
       "mean            30.211757                  47.321391             1.654030   \n",
       "std             31.791210                  18.465162             0.528008   \n",
       "min              0.000000                  16.000000             1.000000   \n",
       "25%              8.333333                  32.000000             1.000000   \n",
       "50%             21.111111                  47.000000             2.000000   \n",
       "75%             41.666667                  62.000000             2.000000   \n",
       "max            343.666667                  80.000000             9.000000   \n",
       "\n",
       "       high_cholesterol  body_mass_index  diabetes_binary  \n",
       "count       9602.000000      9602.000000      9602.000000  \n",
       "mean           1.712768        28.924724         0.374714  \n",
       "std            0.740866         7.103111         0.484074  \n",
       "min            1.000000        13.600000         0.000000  \n",
       "25%            1.000000        23.900000         0.000000  \n",
       "50%            2.000000        27.700000         0.000000  \n",
       "75%            2.000000        32.400000         1.000000  \n",
       "max            9.000000        82.900000         1.000000  "
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5. Load NHANES Laboratory Glycohemoglobin Data + Calculate Ground Truth Diabetes Binary\n",
    "\n",
    "print(\"Loading Lab A1C Data...\")\n",
    "\n",
    "ghb_2011 = pd.read_sas(\"./data/nhanes-lab/ghb-2011-12.xpt\", format=\"xport\")\n",
    "ghb_2013 = pd.read_sas(\"./data/nhanes-lab/ghb-2013-14.xpt\", format=\"xport\")\n",
    "\n",
    "print(\"Lab Data Shape:\")\n",
    "print(\"- GHB 2011-2012:\", ghb_2011.shape)\n",
    "print(\"- GHB 2013-2014:\", ghb_2013.shape)\n",
    "\n",
    "print(\"Calculating ground truth with A1C lab data...\")\n",
    "ghb_2011 = ghb_2011[[\"SEQN\", \"LBXGH\"]].rename(columns={\"LBXGH\": \"a1c_2011\"})\n",
    "ghb_2013 = ghb_2013[[\"SEQN\", \"LBXGH\"]].rename(columns={\"LBXGH\": \"a1c_2013\"})\n",
    "\n",
    "# Combine 2011-12 and 2013-14 data\n",
    "ghb = pd.concat([ghb_2011, ghb_2013], ignore_index=True)\n",
    "ghb[\"a1c\"] = ghb[\"a1c_2011\"].combine_first(ghb[\"a1c_2013\"])\n",
    "ghb = ghb.dropna(subset=[\"a1c\"])\n",
    "ghb = ghb.drop_duplicates(subset=[\"SEQN\"], keep=\"first\")\n",
    "\n",
    "# A1C Diabetes Criteria (We include prediabetes as diabetes):\n",
    "#   normal < 5.7\n",
    "#   prediabetes 5.7-6.4\n",
    "#   diabetes >= 6.5\n",
    "ghb[\"diabetes_binary\"] = (ghb[\"a1c\"] >= 5.7).astype(int)\n",
    "\n",
    "selected_columns = [\"SEQN\", \"diabetes_binary\"]\n",
    "ghb = ghb[selected_columns].copy()\n",
    "df = df.merge(ghb, on=\"SEQN\", how=\"inner\")\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee3f3cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting training for train/val/test...\n",
      "Split sizes (train/val/test): 6721 1440 1441\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 6 Noramlize + Split Data into Train/Val/Test:\n",
    "\n",
    "# Normalize all features before splitting\n",
    "feature_cols = [col for col in df.columns if col not in [\"SEQN\", \"diabetes_binary\"]]\n",
    "scaler = StandardScaler()\n",
    "df[feature_cols] = scaler.fit_transform(df[feature_cols])\n",
    "\n",
    "X = df.drop(columns=[\"SEQN\", \"diabetes_binary\"])\n",
    "y = df[\"diabetes_binary\"].astype(int)\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.30, random_state=42, stratify=y\n",
    ")\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.50, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "print(\"Split sizes (train/val/test):\", len(X_train), len(X_val), len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "ed760689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature columns: ['mean_daily_AC', 'sd_daily_AC', 'mean_sedentary_mins', 'mean_vigorous_mins', 'age_in_years_at_screening', 'high_blood_pressure', 'high_cholesterol', 'body_mass_index']\n",
      "Number of features: 8\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[189]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# --- Method 1: Random Forest Feature Importance (Gini/MDI) ---\u001b[39;00m\n\u001b[32m     14\u001b[39m rf_temp = RandomForestClassifier(n_estimators=\u001b[32m200\u001b[39m, class_weight=\u001b[33m\"\u001b[39m\u001b[33mbalanced\u001b[39m\u001b[33m\"\u001b[39m, random_state=\u001b[32m42\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[43mrf_temp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m feature_importance_mdi = pd.DataFrame({\n\u001b[32m     18\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mfeature\u001b[39m\u001b[33m'\u001b[39m: X.columns,\n\u001b[32m     19\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mimportance_mdi\u001b[39m\u001b[33m'\u001b[39m: rf_temp.feature_importances_\n\u001b[32m     20\u001b[39m }).sort_values(\u001b[33m'\u001b[39m\u001b[33mimportance_mdi\u001b[39m\u001b[33m'\u001b[39m, ascending=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     22\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- Method 1: Mean Decrease in Impurity (Gini) ---\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nnnev\\Desktop\\Git Repos and Coding\\CS3402\\DiaPredict\\diapredict\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nnnev\\Desktop\\Git Repos and Coding\\CS3402\\DiaPredict\\diapredict\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:486\u001b[39m, in \u001b[36mBaseForest.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    475\u001b[39m trees = [\n\u001b[32m    476\u001b[39m     \u001b[38;5;28mself\u001b[39m._make_estimator(append=\u001b[38;5;28;01mFalse\u001b[39;00m, random_state=random_state)\n\u001b[32m    477\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[32m    478\u001b[39m ]\n\u001b[32m    480\u001b[39m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[32m    481\u001b[39m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[32m    482\u001b[39m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[32m    483\u001b[39m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[32m    484\u001b[39m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[32m    485\u001b[39m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m486\u001b[39m trees = \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mthreads\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    501\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    502\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    503\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    504\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    505\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    507\u001b[39m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[32m    508\u001b[39m \u001b[38;5;28mself\u001b[39m.estimators_.extend(trees)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nnnev\\Desktop\\Git Repos and Coding\\CS3402\\DiaPredict\\diapredict\\Lib\\site-packages\\sklearn\\utils\\parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nnnev\\Desktop\\Git Repos and Coding\\CS3402\\DiaPredict\\diapredict\\Lib\\site-packages\\joblib\\parallel.py:1986\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1984\u001b[39m     output = \u001b[38;5;28mself\u001b[39m._get_sequential_output(iterable)\n\u001b[32m   1985\u001b[39m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m1986\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1988\u001b[39m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[32m   1989\u001b[39m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[32m   1990\u001b[39m \u001b[38;5;66;03m# reused, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[32m   1991\u001b[39m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[32m   1992\u001b[39m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[32m   1993\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nnnev\\Desktop\\Git Repos and Coding\\CS3402\\DiaPredict\\diapredict\\Lib\\site-packages\\joblib\\parallel.py:1914\u001b[39m, in \u001b[36mParallel._get_sequential_output\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1912\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_batches += \u001b[32m1\u001b[39m\n\u001b[32m   1913\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_tasks += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1914\u001b[39m res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1915\u001b[39m \u001b[38;5;28mself\u001b[39m.n_completed_tasks += \u001b[32m1\u001b[39m\n\u001b[32m   1916\u001b[39m \u001b[38;5;28mself\u001b[39m.print_progress()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nnnev\\Desktop\\Git Repos and Coding\\CS3402\\DiaPredict\\diapredict\\Lib\\site-packages\\sklearn\\utils\\parallel.py:147\u001b[39m, in \u001b[36m_FuncWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(**config), warnings.catch_warnings():\n\u001b[32m    146\u001b[39m     warnings.filters = warning_filters\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nnnev\\Desktop\\Git Repos and Coding\\CS3402\\DiaPredict\\diapredict\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:188\u001b[39m, in \u001b[36m_parallel_build_trees\u001b[39m\u001b[34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap, missing_values_in_feature_mask)\u001b[39m\n\u001b[32m    185\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m class_weight == \u001b[33m\"\u001b[39m\u001b[33mbalanced_subsample\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    186\u001b[39m         curr_sample_weight *= compute_sample_weight(\u001b[33m\"\u001b[39m\u001b[33mbalanced\u001b[39m\u001b[33m\"\u001b[39m, y, indices=indices)\n\u001b[32m--> \u001b[39m\u001b[32m188\u001b[39m     \u001b[43mtree\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    189\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    190\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    196\u001b[39m     tree._fit(\n\u001b[32m    197\u001b[39m         X,\n\u001b[32m    198\u001b[39m         y,\n\u001b[32m   (...)\u001b[39m\u001b[32m    201\u001b[39m         missing_values_in_feature_mask=missing_values_in_feature_mask,\n\u001b[32m    202\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nnnev\\Desktop\\Git Repos and Coding\\CS3402\\DiaPredict\\diapredict\\Lib\\site-packages\\sklearn\\tree\\_classes.py:472\u001b[39m, in \u001b[36mBaseDecisionTree._fit\u001b[39m\u001b[34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[39m\n\u001b[32m    461\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    462\u001b[39m     builder = BestFirstTreeBuilder(\n\u001b[32m    463\u001b[39m         splitter,\n\u001b[32m    464\u001b[39m         min_samples_split,\n\u001b[32m   (...)\u001b[39m\u001b[32m    469\u001b[39m         \u001b[38;5;28mself\u001b[39m.min_impurity_decrease,\n\u001b[32m    470\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m472\u001b[39m \u001b[43mbuilder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    474\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.n_outputs_ == \u001b[32m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    475\u001b[39m     \u001b[38;5;28mself\u001b[39m.n_classes_ = \u001b[38;5;28mself\u001b[39m.n_classes_[\u001b[32m0\u001b[39m]\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# 6.33 - (Optional) Feature Importance Analysis\n",
    "# Determine which features are most predictive of diabetes\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "import numpy as np\n",
    "\n",
    "print(\"Feature columns:\", X.columns.tolist())\n",
    "print(f\"Number of features: {X.shape[1]}\")\n",
    "\n",
    "# --- Method 1: Random Forest Feature Importance (Gini/MDI) ---\n",
    "rf_temp = RandomForestClassifier(n_estimators=200, class_weight=\"balanced\", random_state=42)\n",
    "rf_temp.fit(X_train, y_train)\n",
    "\n",
    "feature_importance_mdi = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance_mdi': rf_temp.feature_importances_\n",
    "}).sort_values('importance_mdi', ascending=False)\n",
    "\n",
    "print(\"\\n--- Method 1: Mean Decrease in Impurity (Gini) ---\")\n",
    "print(feature_importance_mdi.to_string(index=False))\n",
    "\n",
    "# --- Method 2: Permutation Importance (more reliable) ---\n",
    "perm_importance = permutation_importance(rf_temp, X_val, y_val, n_repeats=30, random_state=42, n_jobs=-1)\n",
    "\n",
    "feature_importance_perm = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance_perm': perm_importance.importances_mean,\n",
    "    'std': perm_importance.importances_std\n",
    "}).sort_values('importance_perm', ascending=False)\n",
    "\n",
    "print(\"\\n--- Method 2: Permutation Importance ---\")\n",
    "print(feature_importance_perm.to_string(index=False))\n",
    "\n",
    "# --- Method 3: Mutual Information ---\n",
    "mi_scores = mutual_info_classif(X_train, y_train, random_state=42)\n",
    "feature_importance_mi = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'mutual_info': mi_scores\n",
    "}).sort_values('mutual_info', ascending=False)\n",
    "\n",
    "print(\"\\n--- Method 3: Mutual Information ---\")\n",
    "print(feature_importance_mi.to_string(index=False))\n",
    "\n",
    "# --- Method 4: Correlation with target ---\n",
    "correlations = X_train.corrwith(y_train).abs().sort_values(ascending=False)\n",
    "print(\"\\n--- Method 4: Absolute Correlation with Target ---\")\n",
    "print(correlations)\n",
    "\n",
    "# --- Visualization ---\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Plot 1: MDI Importance\n",
    "ax1 = axes[0, 0]\n",
    "feature_importance_mdi_sorted = feature_importance_mdi.sort_values('importance_mdi', ascending=True)\n",
    "ax1.barh(feature_importance_mdi_sorted['feature'], feature_importance_mdi_sorted['importance_mdi'], color='steelblue')\n",
    "ax1.set_xlabel('Importance')\n",
    "ax1.set_title('Random Forest Feature Importance (MDI/Gini)')\n",
    "\n",
    "# Plot 2: Permutation Importance\n",
    "ax2 = axes[0, 1]\n",
    "feature_importance_perm_sorted = feature_importance_perm.sort_values('importance_perm', ascending=True)\n",
    "ax2.barh(feature_importance_perm_sorted['feature'], feature_importance_perm_sorted['importance_perm'], \n",
    "         xerr=feature_importance_perm_sorted['std'], color='coral')\n",
    "ax2.set_xlabel('Mean Accuracy Decrease')\n",
    "ax2.set_title('Permutation Importance')\n",
    "\n",
    "# Plot 3: Mutual Information\n",
    "ax3 = axes[1, 0]\n",
    "feature_importance_mi_sorted = feature_importance_mi.sort_values('mutual_info', ascending=True)\n",
    "ax3.barh(feature_importance_mi_sorted['feature'], feature_importance_mi_sorted['mutual_info'], color='seagreen')\n",
    "ax3.set_xlabel('Mutual Information')\n",
    "ax3.set_title('Mutual Information Score')\n",
    "\n",
    "# Plot 4: Feature Correlation Matrix\n",
    "ax4 = axes[1, 1]\n",
    "corr_matrix = X_train.corr()\n",
    "im = ax4.imshow(corr_matrix, cmap='coolwarm', aspect='auto', vmin=-1, vmax=1)\n",
    "ax4.set_xticks(range(len(X.columns)))\n",
    "ax4.set_yticks(range(len(X.columns)))\n",
    "ax4.set_xticklabels(X.columns, rotation=45, ha='right', fontsize=8)\n",
    "ax4.set_yticklabels(X.columns, fontsize=8)\n",
    "ax4.set_title('Feature Correlation Matrix')\n",
    "plt.colorbar(im, ax=ax4)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- Summary: Identify redundant features ---\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ANALYSIS SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Find highly correlated feature pairs (potential redundancy)\n",
    "print(\"\\nHighly Correlated Feature Pairs (|r| > 0.7):\")\n",
    "for i in range(len(corr_matrix.columns)):\n",
    "    for j in range(i+1, len(corr_matrix.columns)):\n",
    "        if abs(corr_matrix.iloc[i, j]) > 0.7:\n",
    "            print(f\"  {corr_matrix.columns[i]} <-> {corr_matrix.columns[j]}: {corr_matrix.iloc[i, j]:.3f}\")\n",
    "\n",
    "# Rank features by average rank across methods\n",
    "ranks = pd.DataFrame({'feature': X.columns})\n",
    "ranks['rank_mdi'] = feature_importance_mdi.set_index('feature').loc[X.columns, 'importance_mdi'].rank(ascending=False)\n",
    "ranks['rank_perm'] = feature_importance_perm.set_index('feature').loc[X.columns, 'importance_perm'].rank(ascending=False)\n",
    "ranks['rank_mi'] = feature_importance_mi.set_index('feature').loc[X.columns, 'mutual_info'].rank(ascending=False)\n",
    "ranks['avg_rank'] = ranks[['rank_mdi', 'rank_perm', 'rank_mi']].mean(axis=1)\n",
    "ranks = ranks.sort_values('avg_rank')\n",
    "\n",
    "print(\"\\n--- Overall Feature Ranking (lower = more important) ---\")\n",
    "print(ranks.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "2cabb24c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 450 candidates, totalling 1350 fits\n",
      "Best parameters found:\n",
      "{'class_weight': 'balanced', 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 500}\n",
      "Best F1 score: 0.6643\n",
      "Validation F1: 0.660828025477707\n",
      "Test F1: 0.6877534468775345\n",
      "Best parameters found:\n",
      "{'class_weight': 'balanced', 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 500}\n",
      "Best F1 score: 0.6643\n",
      "Validation F1: 0.660828025477707\n",
      "Test F1: 0.6877534468775345\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "\n",
    "# 6.67 - (Optional) Hyperparameter Tuning for Random Forest with GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000],\n",
    "    'max_depth': [5, 10, 15, 20, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=param_grid,\n",
    "    scoring=make_scorer(f1_score),\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters found:\")\n",
    "print(grid_search.best_params_)\n",
    "print(f\"Best F1 score: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Use best estimator to predict on validation and test sets\n",
    "y_val_pred = grid_search.best_estimator_.predict(X_val)\n",
    "y_test_pred = grid_search.best_estimator_.predict(X_test)\n",
    "\n",
    "print(\"Validation F1:\", f1_score(y_val, y_val_pred))\n",
    "print(\"Test F1:\", f1_score(y_test, y_test_pred))\n",
    "\n",
    "# Best parameters found:\n",
    "# {'class_weight': 'balanced', 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 500}\n",
    "# Best F1 score: 0.6643\n",
    "# Validation F1: 0.660828025477707\n",
    "# Test F1: 0.6877534468775345"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "60d7402e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation threshold: 0.5293969849246231 F1: 0.6672283066554339\n",
      "\n",
      "Random Forest Model Results:\n",
      "Test Precision: 0.6326530612244898\n",
      "Test Recall: 0.7462962962962963\n",
      "Test F1: 0.6847918436703483\n",
      "Test PR AUC: 0.683751003481257\n",
      "Confusion Matrix:\n",
      " [[667 234]\n",
      " [137 403]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, average_precision_score, confusion_matrix\n",
    "\n",
    "# 7. Train Random Forest Model\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=500, class_weight=\"balanced\", random_state=42, max_depth=5, min_samples_leaf=1, min_samples_split=2)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# choose threshold by maximizing F1 on validation\n",
    "y_val_prob = rf_model.predict_proba(X_val)[:, 1]\n",
    "best_t, best_f1 = 0.0, -1.0\n",
    "for t in np.linspace(0.05, 0.95, 200):\n",
    "    preds = (y_val_prob >= t).astype(int)\n",
    "    score = f1_score(y_val, preds)\n",
    "    if score > best_f1:\n",
    "        best_f1 = score\n",
    "        best_t = t\n",
    "print(\"Best validation threshold:\", best_t, \"F1:\", best_f1)\n",
    "\n",
    "y_test_prob = rf_model.predict_proba(X_test)[:, 1]\n",
    "y_test_pred = (y_test_prob >= best_t).astype(int)\n",
    "\n",
    "print(\"\\nRandom Forest Model Results:\")\n",
    "print(\"Test Precision:\", precision_score(y_test, y_test_pred))\n",
    "print(\"Test Recall:\", recall_score(y_test, y_test_pred))\n",
    "print(\"Test F1:\", f1_score(y_test, y_test_pred))\n",
    "print(\"Test PR AUC:\", average_precision_score(y_test, y_test_prob))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_test_pred))\n",
    "\n",
    "\n",
    "# Best validation threshold: 0.5293969849246231 F1: 0.6672283066554339\n",
    "# Test Precision: 0.6326530612244898\n",
    "# Test Recall: 0.7462962962962963\n",
    "# Test F1: 0.6847918436703483\n",
    "# Test PR AUC: 0.683767879801558\n",
    "# Confusion Matrix:\n",
    "#  [[667 234]\n",
    "#  [137 403]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "4ba26b71",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[198]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     13\u001b[39m xgb = XGBClassifier(random_state=\u001b[32m42\u001b[39m, eval_metric=\u001b[33m'\u001b[39m\u001b[33mlogloss\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     14\u001b[39m grid_search = GridSearchCV(xgb, param_grid, scoring=\u001b[33m'\u001b[39m\u001b[33mf1\u001b[39m\u001b[33m'\u001b[39m, cv=\u001b[32m3\u001b[39m, n_jobs=-\u001b[32m1\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[43mgrid_search\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBest parameters found:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     18\u001b[39m \u001b[38;5;28mprint\u001b[39m(grid_search.best_params_)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nnnev\\Desktop\\Git Repos and Coding\\CS3402\\DiaPredict\\diapredict\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nnnev\\Desktop\\Git Repos and Coding\\CS3402\\DiaPredict\\diapredict\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1045\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1046\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1047\u001b[39m     )\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1051\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1053\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1054\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1055\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nnnev\\Desktop\\Git Repos and Coding\\CS3402\\DiaPredict\\diapredict\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1605\u001b[39m, in \u001b[36mGridSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1603\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1604\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1605\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nnnev\\Desktop\\Git Repos and Coding\\CS3402\\DiaPredict\\diapredict\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:997\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    989\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose > \u001b[32m0\u001b[39m:\n\u001b[32m    990\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    991\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m candidates,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    992\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m fits\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    993\u001b[39m             n_splits, n_candidates, n_candidates * n_splits\n\u001b[32m    994\u001b[39m         )\n\u001b[32m    995\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m997\u001b[39m out = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    998\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    999\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1000\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1001\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1002\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1003\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1004\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1005\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1006\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1007\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1008\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) < \u001b[32m1\u001b[39m:\n\u001b[32m   1016\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1017\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo fits were performed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1018\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWas the CV iterator empty? \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1019\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWere there no candidates?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1020\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nnnev\\Desktop\\Git Repos and Coding\\CS3402\\DiaPredict\\diapredict\\Lib\\site-packages\\sklearn\\utils\\parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nnnev\\Desktop\\Git Repos and Coding\\CS3402\\DiaPredict\\diapredict\\Lib\\site-packages\\joblib\\parallel.py:2072\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2070\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nnnev\\Desktop\\Git Repos and Coding\\CS3402\\DiaPredict\\diapredict\\Lib\\site-packages\\joblib\\parallel.py:1682\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1688\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nnnev\\Desktop\\Git Repos and Coding\\CS3402\\DiaPredict\\diapredict\\Lib\\site-packages\\joblib\\parallel.py:1800\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_ordered:\n\u001b[32m   1790\u001b[39m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[32m   1791\u001b[39m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1795\u001b[39m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[32m   1796\u001b[39m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[32m   1797\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1798\u001b[39m         \u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING\n\u001b[32m   1799\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1800\u001b[39m         \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1801\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1803\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs == \u001b[32m0\u001b[39m:\n\u001b[32m   1804\u001b[39m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[32m   1805\u001b[39m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1811\u001b[39m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[32m   1812\u001b[39m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 7.5 - (Optional) Hyperparameter Tuning for XGBoost with GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 6, 9],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'scale_pos_weight': [1, 2, 5]\n",
    "}\n",
    "\n",
    "xgb = XGBClassifier(random_state=42, eval_metric='logloss')\n",
    "grid_search = GridSearchCV(xgb, param_grid, scoring='f1', cv=3, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters found:\")\n",
    "print(grid_search.best_params_)\n",
    "print(f\"Best F1 score: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Use best estimator to predict on validation and test sets\n",
    "y_val_pred = grid_search.best_estimator_.predict(X_val)\n",
    "y_test_pred = grid_search.best_estimator_.predict(X_test)\n",
    "\n",
    "print(\"Validation F1:\", f1_score(y_val, y_val_pred))\n",
    "print(\"Test F1:\", f1_score(y_test, y_test_pred))\n",
    "\n",
    "# Best parameters found:\n",
    "# {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 300, 'scale_pos_weight': 2}\n",
    "# Best F1 score: 0.6680\n",
    "# Validation F1: 0.65424739195231\n",
    "# Test F1: 0.6771771771771772"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "dd97a1f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost - Best validation threshold: 0.6062814070351759 F1: 0.6683673469387755\n",
      "\n",
      "XGBoost Model Results:\n",
      "Test Precision: 0.6271450858034321\n",
      "Test Recall: 0.7444444444444445\n",
      "Test F1: 0.68077900084674\n",
      "Test PR AUC: 0.6860215471025365\n",
      "Confusion Matrix:\n",
      " [[662 239]\n",
      " [138 402]]\n"
     ]
    }
   ],
   "source": [
    "# 8. Train XGBoost Model\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=3,\n",
    "    learning_rate=0.01,\n",
    "    scale_pos_weight=2,\n",
    "    random_state=42,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Threshold tuning on validation set\n",
    "y_val_prob_xgb = xgb_model.predict_proba(X_val)[:, 1]\n",
    "best_t_xgb, best_f1_xgb = 0.0, -1.0\n",
    "for t in np.linspace(0.05, 0.95, 200):\n",
    "    preds = (y_val_prob_xgb >= t).astype(int)\n",
    "    score = f1_score(y_val, preds)\n",
    "    if score > best_f1_xgb:\n",
    "        best_f1_xgb = score\n",
    "        best_t_xgb = t\n",
    "print(\"XGBoost - Best validation threshold:\", best_t_xgb, \"F1:\", best_f1_xgb)\n",
    "\n",
    "y_test_prob_xgb = xgb_model.predict_proba(X_test)[:, 1]\n",
    "y_test_pred_xgb = (y_test_prob_xgb >= best_t_xgb).astype(int)\n",
    "\n",
    "print(\"\\nXGBoost Model Results:\")\n",
    "print(\"Test Precision:\", precision_score(y_test, y_test_pred_xgb))\n",
    "print(\"Test Recall:\", recall_score(y_test, y_test_pred_xgb))\n",
    "print(\"Test F1:\", f1_score(y_test, y_test_pred_xgb))\n",
    "print(\"Test PR AUC:\", average_precision_score(y_test, y_test_prob_xgb))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_test_pred_xgb))\n",
    "\n",
    "# Test Precision: 0.6271450858034321\n",
    "# Test Recall: 0.7444444444444445\n",
    "# Test F1: 0.68077900084674\n",
    "# Test PR AUC: 0.6860215471025365\n",
    "# Confusion Matrix:\n",
    "#  [[662 239]\n",
    "#  [138 402]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "1fd38f3d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[200]\u001b[39m\u001b[32m, line 30\u001b[39m\n\u001b[32m     21\u001b[39m mlp = MLPClassifier(\n\u001b[32m     22\u001b[39m     random_state=\u001b[32m42\u001b[39m,\n\u001b[32m     23\u001b[39m     max_iter=\u001b[32m500\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     26\u001b[39m     n_iter_no_change=\u001b[32m10\u001b[39m\n\u001b[32m     27\u001b[39m )\n\u001b[32m     29\u001b[39m grid_search = GridSearchCV(mlp, param_grid, scoring=\u001b[33m'\u001b[39m\u001b[33mf1\u001b[39m\u001b[33m'\u001b[39m, cv=\u001b[32m5\u001b[39m, n_jobs=-\u001b[32m1\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m \u001b[43mgrid_search\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBest parameters found:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     33\u001b[39m \u001b[38;5;28mprint\u001b[39m(grid_search.best_params_)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nnnev\\Desktop\\Git Repos and Coding\\CS3402\\DiaPredict\\diapredict\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nnnev\\Desktop\\Git Repos and Coding\\CS3402\\DiaPredict\\diapredict\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1045\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1046\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1047\u001b[39m     )\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1051\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1053\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1054\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1055\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nnnev\\Desktop\\Git Repos and Coding\\CS3402\\DiaPredict\\diapredict\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1605\u001b[39m, in \u001b[36mGridSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1603\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1604\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1605\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nnnev\\Desktop\\Git Repos and Coding\\CS3402\\DiaPredict\\diapredict\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:997\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    989\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose > \u001b[32m0\u001b[39m:\n\u001b[32m    990\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    991\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m candidates,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    992\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m fits\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    993\u001b[39m             n_splits, n_candidates, n_candidates * n_splits\n\u001b[32m    994\u001b[39m         )\n\u001b[32m    995\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m997\u001b[39m out = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    998\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    999\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1000\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1001\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1002\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1003\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1004\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1005\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1006\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1007\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1008\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) < \u001b[32m1\u001b[39m:\n\u001b[32m   1016\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1017\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo fits were performed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1018\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWas the CV iterator empty? \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1019\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWere there no candidates?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1020\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nnnev\\Desktop\\Git Repos and Coding\\CS3402\\DiaPredict\\diapredict\\Lib\\site-packages\\sklearn\\utils\\parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nnnev\\Desktop\\Git Repos and Coding\\CS3402\\DiaPredict\\diapredict\\Lib\\site-packages\\joblib\\parallel.py:2072\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2070\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nnnev\\Desktop\\Git Repos and Coding\\CS3402\\DiaPredict\\diapredict\\Lib\\site-packages\\joblib\\parallel.py:1682\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1688\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nnnev\\Desktop\\Git Repos and Coding\\CS3402\\DiaPredict\\diapredict\\Lib\\site-packages\\joblib\\parallel.py:1800\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_ordered:\n\u001b[32m   1790\u001b[39m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[32m   1791\u001b[39m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1795\u001b[39m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[32m   1796\u001b[39m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[32m   1797\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1798\u001b[39m         \u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING\n\u001b[32m   1799\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1800\u001b[39m         \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1801\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1803\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs == \u001b[32m0\u001b[39m:\n\u001b[32m   1804\u001b[39m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[32m   1805\u001b[39m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1811\u001b[39m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[32m   1812\u001b[39m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 8.5 - (Optional) Hyperparameter Tuning for MLP Neural Network with GridSearchCV\n",
    "\n",
    "# Data is already normalized above, so no need to scale again\n",
    "X_train_scaled = X_train\n",
    "X_val_scaled = X_val\n",
    "X_test_scaled = X_test\n",
    "\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(64,), (64, 32), (64, 32, 16), (128, 64), (128, 64, 32)],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'learning_rate': ['constant', 'adaptive'],\n",
    "    'learning_rate_init': [0.001, 0.01],\n",
    "    'alpha': [0.0001, 0.001, 0.01],\n",
    "}\n",
    "\n",
    "# Use early_stopping in the base estimator to prevent overfitting\n",
    "mlp = MLPClassifier(\n",
    "    random_state=42,\n",
    "    max_iter=500,\n",
    "    early_stopping=True,\n",
    "    validation_fraction=0.1,\n",
    "    n_iter_no_change=10\n",
    ")\n",
    "\n",
    "grid_search = GridSearchCV(mlp, param_grid, scoring='f1', cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Best parameters found:\")\n",
    "print(grid_search.best_params_)\n",
    "print(f\"Best CV F1 score: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Evaluate on validation and test sets\n",
    "y_val_pred = grid_search.best_estimator_.predict(X_val_scaled)\n",
    "y_test_pred = grid_search.best_estimator_.predict(X_test_scaled)\n",
    "\n",
    "print(f\"\\nValidation F1: {f1_score(y_val, y_val_pred):.4f}\")\n",
    "print(f\"Test F1: {f1_score(y_test, y_test_pred):.4f}\")\n",
    "\n",
    "# Best parameters found:\n",
    "# {'activation': 'relu', 'alpha': 0.01, 'hidden_layer_sizes': (64, 32, 16), 'learning_rate': 'constant', 'learning_rate_init': 0.01}\n",
    "# Best CV F1 score: 0.6419\n",
    "\n",
    "# Validation F1: 0.6486\n",
    "# Test F1: 0.6685"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "d52e67b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP - Best validation threshold: 0.3846733668341708 F1: 0.6697892271662763\n",
      "\n",
      "MLP Neural Network Model Results:\n",
      "Test Precision: 0.5978260869565217\n",
      "Test Recall: 0.8148148148148148\n",
      "Test F1: 0.6896551724137931\n",
      "Test PR AUC: 0.6785797040829918\n",
      "Confusion Matrix:\n",
      " [[605 296]\n",
      " [100 440]]\n"
     ]
    }
   ],
   "source": [
    "# 9. Train Neural Network (MLP)\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Data is already normalized above, so no need to scale again\n",
    "X_train_scaled = X_train\n",
    "X_val_scaled = X_val\n",
    "X_test_scaled = X_test\n",
    "\n",
    "# Calculate class weights for the loss function\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "sample_weights = compute_sample_weight('balanced', y_train)\n",
    "\n",
    "mlp_model = MLPClassifier(\n",
    "    hidden_layer_sizes=(64, 32, 16),\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    learning_rate='constant',\n",
    "    learning_rate_init=0.01,\n",
    "    max_iter=500,\n",
    "    early_stopping=True,\n",
    "    validation_fraction=0.1,\n",
    "    random_state=42,\n",
    "    verbose=False,\n",
    "    alpha=0.01,\n",
    ")\n",
    "mlp_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Threshold tuning on validation set\n",
    "y_val_prob_mlp = mlp_model.predict_proba(X_val_scaled)[:, 1]\n",
    "best_t_mlp, best_f1_mlp = 0.0, -1.0\n",
    "for t in np.linspace(0.05, 0.95, 200):\n",
    "    preds = (y_val_prob_mlp >= t).astype(int)\n",
    "    score = f1_score(y_val, preds)\n",
    "    if score > best_f1_mlp:\n",
    "        best_f1_mlp = score\n",
    "        best_t_mlp = t\n",
    "print(\"MLP - Best validation threshold:\", best_t_mlp, \"F1:\", best_f1_mlp)\n",
    "\n",
    "y_test_prob_mlp = mlp_model.predict_proba(X_test_scaled)[:, 1]\n",
    "y_test_pred_mlp = (y_test_prob_mlp >= best_t_mlp).astype(int)\n",
    "\n",
    "print(\"\\nMLP Neural Network Model Results:\")\n",
    "print(\"Test Precision:\", precision_score(y_test, y_test_pred_mlp))\n",
    "print(\"Test Recall:\", recall_score(y_test, y_test_pred_mlp))\n",
    "print(\"Test F1:\", f1_score(y_test, y_test_pred_mlp))\n",
    "print(\"Test PR AUC:\", average_precision_score(y_test, y_test_prob_mlp))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_test_pred_mlp))\n",
    "\n",
    "# Test Precision: 0.6071428571428571\n",
    "# Test Recall: 0.7870370370370371\n",
    "# Test F1: 0.6854838709677419\n",
    "# Test PR AUC: 0.6772435565180253\n",
    "# Confusion Matrix:\n",
    "#  [[626 275]\n",
    "#  [115 425]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "71001402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned weights - RF: 0.332, XGB: 0.335, MLP: 0.333\n",
      "\n",
      "Final Weighted Avg. Ensemble Model Results:\n",
      "Threshold: 0.463\n",
      "Precision: 0.5995\n",
      "Recall: 0.8315\n",
      "F1: 0.6967\n",
      "PR AUC: 0.6879\n",
      "Confusion Matrix:\n",
      "[[601 300]\n",
      " [ 91 449]]\n",
      "\n",
      "Final Weighted Avg. Ensemble Model Results:\n",
      "Threshold: 0.463\n",
      "Precision: 0.5995\n",
      "Recall: 0.8315\n",
      "F1: 0.6967\n",
      "PR AUC: 0.6879\n",
      "Confusion Matrix:\n",
      "[[601 300]\n",
      " [ 91 449]]\n"
     ]
    }
   ],
   "source": [
    "# 10. Ensemble Methods - Combining RF, XGBoost, and MLP\n",
    "\n",
    "# Get probability predictions from all models\n",
    "probs_rf = rf_model.predict_proba(X_test)[:, 1]\n",
    "probs_xgb = xgb_model.predict_proba(X_test)[:, 1]\n",
    "probs_mlp = mlp_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Get validation probabilities for threshold tuning\n",
    "val_probs_rf = rf_model.predict_proba(X_val)[:, 1]\n",
    "val_probs_xgb = xgb_model.predict_proba(X_val)[:, 1]\n",
    "val_probs_mlp = mlp_model.predict_proba(X_val_scaled)[:, 1]\n",
    "\n",
    "# Calculate Weights for Weighted Average based on validation PR-AUC\n",
    "w_rf = average_precision_score(y_val, val_probs_rf)\n",
    "w_xgb = average_precision_score(y_val, val_probs_xgb)\n",
    "w_mlp = average_precision_score(y_val, val_probs_mlp)\n",
    "total_w = w_rf + w_xgb + w_mlp\n",
    "w_rf, w_xgb, w_mlp = w_rf/total_w, w_xgb/total_w, w_mlp/total_w\n",
    "print(f\"Learned weights - RF: {w_rf:.3f}, XGB: {w_xgb:.3f}, MLP: {w_mlp:.3f}\")\n",
    "\n",
    "ensemble_weighted_val = w_rf * val_probs_rf + w_xgb * val_probs_xgb + w_mlp * val_probs_mlp\n",
    "ensemble_weighted_test = w_rf * probs_rf + w_xgb * probs_xgb + w_mlp * probs_mlp\n",
    "\n",
    "# Find threshold that achieves ~95% recall\n",
    "target_recall=0.80\n",
    "best_t, best_f1 = 0.0, -1.0\n",
    "for t in np.linspace(0.01, 0.95, 300):\n",
    "    preds = (ensemble_weighted_val >= t).astype(int)\n",
    "    rec = recall_score(y_val, preds)\n",
    "    if rec >= target_recall:\n",
    "        f1 = f1_score(y_val, preds)\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_t = t\n",
    "\n",
    "\n",
    "y_pred = (ensemble_weighted_test >= best_t).astype(int)\n",
    "\n",
    "prec = precision_score(y_test, y_pred)\n",
    "rec = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "pr_auc = average_precision_score(y_test, ensemble_weighted_test)\n",
    "\n",
    "print(f\"\\nFinal Weighted Avg. Ensemble Model Results:\")\n",
    "print(f\"Threshold: {best_t:.3f}\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"Recall: {rec:.4f}\")\n",
    "print(f\"F1: {f1:.4f}\")\n",
    "print(f\"PR AUC: {pr_auc:.4f}\")\n",
    "print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, y_pred)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diapredict (3.12.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
