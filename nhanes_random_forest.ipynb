{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755d75cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    f1_score, precision_score, recall_score,\n",
    "    average_precision_score, confusion_matrix\n",
    ")\n",
    "\n",
    "# 1. Setup Data Paths\n",
    "nhanes_step_count_dir = \"./data/nhanes-step-count/\"\n",
    "subject_info_path = os.path.join(nhanes_step_count_dir, \"subject-info.csv\")\n",
    "actisteps_path = os.path.join(nhanes_step_count_dir, \"nhanes_1440_actisteps.csv.xz\")\n",
    "ac_path = os.path.join(nhanes_step_count_dir, \"nhanes_1440_AC.csv.xz\")\n",
    "mims_path = os.path.join(nhanes_step_count_dir, \"nhanes_1440_PAXMTSM.csv.xz\")\n",
    "\n",
    "nhanes_lab_dir = \"./data/nhanes-lab/\"\n",
    "ghb_path_2011 = os.path.join(nhanes_lab_dir, \"ghb-2011-12.xpt\")\n",
    "ghb_path_2013 = os.path.join(nhanes_lab_dir, \"ghb-2013-14.xpt\")\n",
    "\n",
    "nhanes_questionnaire_dir = \"./data/nhanes-questionnaire/\"\n",
    "bpq_path_2011 = os.path.join(nhanes_questionnaire_dir, \"bpq-2011-12.xpt\")\n",
    "bpq_path_2013 = os.path.join(nhanes_questionnaire_dir, \"bpq-2013-14.xpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "acd48cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Wearable Movement Data... (this may take a few minutes)\n",
      "Wearable Data Shape:\n",
      "- Subject Info: (19931, 8)\n",
      "- Actisteps: (130186, 1443)\n",
      "- Activity Counts: (130186, 1443)\n",
      "- MIMS: (130186, 1443)\n",
      "Wearable Data Shape:\n",
      "- Subject Info: (19931, 8)\n",
      "- Actisteps: (130186, 1443)\n",
      "- Activity Counts: (130186, 1443)\n",
      "- MIMS: (130186, 1443)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 2. Load NHANES Step-Count Data\n",
    "print(\"Loading Wearable Movement Data... (this may take a few minutes)\")\n",
    "\n",
    "subj_df = pd.read_csv(subject_info_path, dtype={\"SEQN\": \"Int64\"})\n",
    "actisteps_df = pd.read_csv(actisteps_path, dtype={\"SEQN\": \"Int64\"}, low_memory=False)\n",
    "ac_df = pd.read_csv(ac_path, dtype={\"SEQN\": \"Int64\"}, low_memory=False)\n",
    "mims_df = pd.read_csv(mims_path, dtype={\"SEQN\": \"Int64\"}, low_memory=False)\n",
    "\n",
    "print(\"Wearable Data Shape:\")\n",
    "print(\"- Subject Info:\", subj_df.shape)\n",
    "print(\"- Actisteps:\", actisteps_df.shape)\n",
    "print(\"- Activity Counts:\", ac_df.shape)\n",
    "print(\"- MIMS:\", mims_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ef7a5dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Wearable Data Features...\n",
      "['SEQN', 'data_release_cycle', 'gender', 'age_in_years_at_screening', 'full_sample_2_year_interview_weight', 'full_sample_2_year_mec_exam_weight', 'masked_variance_pseudo_psu', 'masked_variance_pseudo_stratum']\n",
      "['SEQN', 'data_release_cycle', 'gender', 'age_in_years_at_screening', 'full_sample_2_year_interview_weight', 'full_sample_2_year_mec_exam_weight', 'masked_variance_pseudo_psu', 'masked_variance_pseudo_stratum']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEQN</th>\n",
       "      <th>mean_daily_steps</th>\n",
       "      <th>sd_daily_steps</th>\n",
       "      <th>mean_daily_AC</th>\n",
       "      <th>sd_daily_AC</th>\n",
       "      <th>mean_daily_mims</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>14685.0</td>\n",
       "      <td>14685.000000</td>\n",
       "      <td>14685.000000</td>\n",
       "      <td>1.468500e+04</td>\n",
       "      <td>1.468500e+04</td>\n",
       "      <td>14685.000000</td>\n",
       "      <td>14685.000000</td>\n",
       "      <td>14685.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>73183.777528</td>\n",
       "      <td>9696.561159</td>\n",
       "      <td>4827.944617</td>\n",
       "      <td>2.151068e+06</td>\n",
       "      <td>1.063271e+06</td>\n",
       "      <td>11352.391422</td>\n",
       "      <td>0.510861</td>\n",
       "      <td>35.753899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6486.391406</td>\n",
       "      <td>3703.772504</td>\n",
       "      <td>1902.143937</td>\n",
       "      <td>8.833311e+05</td>\n",
       "      <td>4.435279e+05</td>\n",
       "      <td>4329.524632</td>\n",
       "      <td>0.499899</td>\n",
       "      <td>23.184655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>62161.0</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.256192e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.344667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>67313.0</td>\n",
       "      <td>7313.111111</td>\n",
       "      <td>3593.250270</td>\n",
       "      <td>1.571732e+06</td>\n",
       "      <td>7.575077e+05</td>\n",
       "      <td>8623.339000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>74099.0</td>\n",
       "      <td>9805.111111</td>\n",
       "      <td>4756.055824</td>\n",
       "      <td>2.129310e+06</td>\n",
       "      <td>1.028943e+06</td>\n",
       "      <td>11335.417778</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>33.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>78971.0</td>\n",
       "      <td>12158.666667</td>\n",
       "      <td>5954.645665</td>\n",
       "      <td>2.734121e+06</td>\n",
       "      <td>1.333755e+06</td>\n",
       "      <td>14213.382000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>55.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>83731.0</td>\n",
       "      <td>29042.222222</td>\n",
       "      <td>18750.860952</td>\n",
       "      <td>7.206275e+06</td>\n",
       "      <td>7.410255e+06</td>\n",
       "      <td>35693.532444</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>80.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               SEQN  mean_daily_steps  sd_daily_steps  mean_daily_AC  \\\n",
       "count       14685.0      14685.000000    14685.000000   1.468500e+04   \n",
       "mean   73183.777528       9696.561159     4827.944617   2.151068e+06   \n",
       "std     6486.391406       3703.772504     1902.143937   8.833311e+05   \n",
       "min         62161.0          1.500000        0.000000   1.256192e+02   \n",
       "25%         67313.0       7313.111111     3593.250270   1.571732e+06   \n",
       "50%         74099.0       9805.111111     4756.055824   2.129310e+06   \n",
       "75%         78971.0      12158.666667     5954.645665   2.734121e+06   \n",
       "max         83731.0      29042.222222    18750.860952   7.206275e+06   \n",
       "\n",
       "        sd_daily_AC  mean_daily_mims        gender           age  \n",
       "count  1.468500e+04     14685.000000  14685.000000  14685.000000  \n",
       "mean   1.063271e+06     11352.391422      0.510861     35.753899  \n",
       "std    4.435279e+05      4329.524632      0.499899     23.184655  \n",
       "min    0.000000e+00         1.344667      0.000000      3.000000  \n",
       "25%    7.575077e+05      8623.339000      0.000000     14.000000  \n",
       "50%    1.028943e+06     11335.417778      1.000000     33.000000  \n",
       "75%    1.333755e+06     14213.382000      1.000000     55.000000  \n",
       "max    7.410255e+06     35693.532444      1.000000     80.000000  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Feature Engineering for NHANES Step-Count Data\n",
    "print(\"Computing Wearable Data Features...\")\n",
    "\n",
    "# Compute Daily Step Statistics\n",
    "actisteps_minute_cols = [c for c in actisteps_df.columns if c.startswith(\"min_\")]\n",
    "actisteps_df[\"daily_steps\"] = actisteps_df[actisteps_minute_cols].sum(axis=1, numeric_only=True)\n",
    "actisteps_df[\"valid_day\"] = actisteps_df[\"daily_steps\"] > 0\n",
    "actisteps_df = actisteps_df[actisteps_df[\"valid_day\"]]\n",
    "actisteps_agg = actisteps_df.groupby(\"SEQN\").agg(\n",
    "    mean_daily_steps=(\"daily_steps\", \"mean\"),\n",
    "    sd_daily_steps=(\"daily_steps\", \"std\"),\n",
    ").reset_index()\n",
    "actisteps_agg[\"sd_daily_steps\"] = actisteps_agg[\"sd_daily_steps\"].fillna(0.0)\n",
    "\n",
    "selected_columns = [\"SEQN\", \"mean_daily_steps\", \"sd_daily_steps\"]\n",
    "df = actisteps_agg[selected_columns].copy()\n",
    "\n",
    "# Compute Activity Counts Features\n",
    "ac_minute_cols = [c for c in ac_df.columns if c.startswith(\"min_\")]\n",
    "ac_df[\"daily_AC\"] = ac_df[ac_minute_cols].sum(axis=1, numeric_only=True)\n",
    "ac_agg = ac_df.groupby(\"SEQN\").agg(\n",
    "    mean_daily_AC=(\"daily_AC\", \"mean\"),\n",
    "    sd_daily_AC=(\"daily_AC\", \"std\")\n",
    ").reset_index()\n",
    "ac_agg[\"sd_daily_AC\"] = ac_agg[\"sd_daily_AC\"].fillna(0.0)\n",
    "\n",
    "selected_columns = [\"SEQN\", \"mean_daily_AC\", \"sd_daily_AC\"]\n",
    "ac_agg = ac_agg[selected_columns].copy()\n",
    "df = df.merge(ac_agg, on=\"SEQN\", how=\"left\")\n",
    "\n",
    "# Compute MIMS (Monitor-Independent Movement Summary) Features\n",
    "mims_minute_cols = [c for c in mims_df.columns if c.startswith(\"min_\")]\n",
    "mims_df[\"daily_mims_sum\"] = mims_df[mims_minute_cols].sum(axis=1, numeric_only=True)\n",
    "mims_agg = mims_df.groupby(\"SEQN\").agg(\n",
    "    mean_daily_mims=(\"daily_mims_sum\", \"mean\"),\n",
    ").reset_index()\n",
    "selected_columns = [\"SEQN\", \"mean_daily_mims\"]\n",
    "mims_agg = mims_agg[selected_columns].copy()\n",
    "df = df.merge(mims_agg, on=\"SEQN\", how=\"left\")\n",
    "\n",
    "# Merge with Subject Info\n",
    "print(subj_df.columns.tolist())\n",
    "selected_columns = [\"SEQN\", \"gender\", \"age_in_years_at_screening\"]\n",
    "subj_df = subj_df[selected_columns].copy()\n",
    "subj_df['gender'] = subj_df['gender'].map({'Male': 0, 'Female': 1})\n",
    "subj_df = subj_df.rename(columns={'age_in_years_at_screening': 'age'})\n",
    "df = df.merge(subj_df, on=\"SEQN\", how=\"left\")\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ce0c34",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/questionnaire/BPQ-2013-14.xpt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 3.5 - Load NHANES Blood Pressure Questionnaire Data + Merge Features\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m bpq_2011 \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_sas\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./data/questionnaire/BPQ-2013-14.xpt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mxport\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m bpq_2013 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_sas(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./data/questionnaire/BPQ-2011-12.xpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxport\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m bpq \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([bpq_2011, bpq_2013], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/CS3402/CS3402/DiaPredict/diapredict/lib/python3.10/site-packages/pandas/io/sas/sasreader.py:154\u001b[0m, in \u001b[0;36mread_sas\u001b[0;34m(filepath_or_buffer, format, index, encoding, chunksize, iterator, compression)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxport\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msas_xport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m XportReader\n\u001b[0;32m--> 154\u001b[0m     reader \u001b[38;5;241m=\u001b[39m \u001b[43mXportReader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msas7bdat\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msas7bdat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SAS7BDATReader\n",
      "File \u001b[0;32m~/CS3402/CS3402/DiaPredict/diapredict/lib/python3.10/site-packages/pandas/io/sas/sas_xport.py:270\u001b[0m, in \u001b[0;36mXportReader.__init__\u001b[0;34m(self, filepath_or_buffer, index, encoding, chunksize, compression)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index \u001b[38;5;241m=\u001b[39m index\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_chunksize \u001b[38;5;241m=\u001b[39m chunksize\n\u001b[0;32m--> 270\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepath_or_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/CS3402/CS3402/DiaPredict/diapredict/lib/python3.10/site-packages/pandas/io/common.py:882\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    883\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[1;32m    885\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/questionnaire/BPQ-2013-14.xpt'"
     ]
    }
   ],
   "source": [
    "# 3.5 - Load NHANES Blood Pressure Questionnaire Data + Merge Features\n",
    "\n",
    "bpq_2011 = pd.read_sas(bpq_path_2011, format=\"xport\")\n",
    "bpq_2013 = pd.read_sas(bpq_path_2013, format=\"xport\")\n",
    "\n",
    "bpq = pd.concat([bpq_2011, bpq_2013], ignore_index=True)\n",
    "# BPQ020: Ever told you had high blood pressure\n",
    "# BPQ080: Doctor told you - high cholesterol level\n",
    "selected_columns = [\"SEQN\", \"BPQ020\", \"BPQ080\"]\n",
    "bpq = bpq[selected_columns].copy()\n",
    "bpq = bpq.dropna()\n",
    "df = df.merge(bpq, on=\"SEQN\", how=\"inner\")\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002b3895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Lab A1C Data...\n",
      "Lab Data Shape:\n",
      "- GHB 2011-2012: (6549, 2)\n",
      "- GHB 2013-2014: (6979, 2)\n",
      "Calculating ground truth with A1C lab data...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEQN</th>\n",
       "      <th>mean_daily_steps</th>\n",
       "      <th>sd_daily_steps</th>\n",
       "      <th>mean_daily_AC</th>\n",
       "      <th>sd_daily_AC</th>\n",
       "      <th>mean_daily_mims</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>diabetes_binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>11297.0</td>\n",
       "      <td>11297.000000</td>\n",
       "      <td>11297.000000</td>\n",
       "      <td>1.129700e+04</td>\n",
       "      <td>1.129700e+04</td>\n",
       "      <td>11297.000000</td>\n",
       "      <td>11297.000000</td>\n",
       "      <td>11297.000000</td>\n",
       "      <td>11297.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>73044.197575</td>\n",
       "      <td>9353.983363</td>\n",
       "      <td>4678.675234</td>\n",
       "      <td>1.988807e+06</td>\n",
       "      <td>9.807107e+05</td>\n",
       "      <td>10539.750274</td>\n",
       "      <td>0.515978</td>\n",
       "      <td>42.759494</td>\n",
       "      <td>0.093742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6492.449564</td>\n",
       "      <td>3656.954725</td>\n",
       "      <td>1938.013479</td>\n",
       "      <td>7.764475e+05</td>\n",
       "      <td>4.030827e+05</td>\n",
       "      <td>3757.227917</td>\n",
       "      <td>0.499767</td>\n",
       "      <td>20.607693</td>\n",
       "      <td>0.291482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>62161.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.862902e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.344667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>67229.0</td>\n",
       "      <td>6989.555556</td>\n",
       "      <td>3390.468444</td>\n",
       "      <td>1.503062e+06</td>\n",
       "      <td>7.124656e+05</td>\n",
       "      <td>8281.954111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>73847.0</td>\n",
       "      <td>9287.222222</td>\n",
       "      <td>4526.853985</td>\n",
       "      <td>1.984948e+06</td>\n",
       "      <td>9.499311e+05</td>\n",
       "      <td>10607.631222</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>78922.0</td>\n",
       "      <td>11617.666667</td>\n",
       "      <td>5782.260395</td>\n",
       "      <td>2.486553e+06</td>\n",
       "      <td>1.213270e+06</td>\n",
       "      <td>12980.228778</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>83729.0</td>\n",
       "      <td>29042.222222</td>\n",
       "      <td>18750.860952</td>\n",
       "      <td>7.206275e+06</td>\n",
       "      <td>7.410255e+06</td>\n",
       "      <td>35693.532444</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               SEQN  mean_daily_steps  sd_daily_steps  mean_daily_AC  \\\n",
       "count       11297.0      11297.000000    11297.000000   1.129700e+04   \n",
       "mean   73044.197575       9353.983363     4678.675234   1.988807e+06   \n",
       "std     6492.449564       3656.954725     1938.013479   7.764475e+05   \n",
       "min         62161.0          3.000000        0.000000   1.862902e+02   \n",
       "25%         67229.0       6989.555556     3390.468444   1.503062e+06   \n",
       "50%         73847.0       9287.222222     4526.853985   1.984948e+06   \n",
       "75%         78922.0      11617.666667     5782.260395   2.486553e+06   \n",
       "max         83729.0      29042.222222    18750.860952   7.206275e+06   \n",
       "\n",
       "        sd_daily_AC  mean_daily_mims        gender           age  \\\n",
       "count  1.129700e+04     11297.000000  11297.000000  11297.000000   \n",
       "mean   9.807107e+05     10539.750274      0.515978     42.759494   \n",
       "std    4.030827e+05      3757.227917      0.499767     20.607693   \n",
       "min    0.000000e+00         1.344667      0.000000     12.000000   \n",
       "25%    7.124656e+05      8281.954111      0.000000     24.000000   \n",
       "50%    9.499311e+05     10607.631222      1.000000     42.000000   \n",
       "75%    1.213270e+06     12980.228778      1.000000     60.000000   \n",
       "max    7.410255e+06     35693.532444      1.000000     80.000000   \n",
       "\n",
       "       diabetes_binary  \n",
       "count     11297.000000  \n",
       "mean          0.093742  \n",
       "std           0.291482  \n",
       "min           0.000000  \n",
       "25%           0.000000  \n",
       "50%           0.000000  \n",
       "75%           0.000000  \n",
       "max           1.000000  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4 Load NHANES Laboratory Glycohemoglobin Data + Calculate Ground Truth Diabetes Binary\n",
    "print(\"Loading Lab A1C Data...\")\n",
    "\n",
    "ghb_2011 = pd.read_sas(\"./data/nhanes-lab/ghb-2011-12.xpt\", format=\"xport\")\n",
    "ghb_2013 = pd.read_sas(\"./data/nhanes-lab/ghb-2013-14.xpt\", format=\"xport\")\n",
    "\n",
    "print(\"Lab Data Shape:\")\n",
    "print(\"- GHB 2011-2012:\", ghb_2011.shape)\n",
    "print(\"- GHB 2013-2014:\", ghb_2013.shape)\n",
    "\n",
    "print(\"Calculating ground truth with A1C lab data...\")\n",
    "ghb_2011 = ghb_2011[[\"SEQN\", \"LBXGH\"]].rename(columns={\"LBXGH\": \"a1c_2011\"})\n",
    "ghb_2013 = ghb_2013[[\"SEQN\", \"LBXGH\"]].rename(columns={\"LBXGH\": \"a1c_2013\"})\n",
    "\n",
    "# Combine 2011-12 and 2013-14 data\n",
    "ghb = pd.concat([ghb_2011, ghb_2013], ignore_index=True)\n",
    "ghb[\"a1c\"] = ghb[\"a1c_2011\"].combine_first(ghb[\"a1c_2013\"])\n",
    "ghb = ghb.dropna(subset=[\"a1c\"])\n",
    "ghb = ghb.drop_duplicates(subset=[\"SEQN\"], keep=\"first\")\n",
    "\n",
    "# A1C Diabetes Criteria (We include prediabetes as diabetes):\n",
    "#   normal < 5.7\n",
    "#   prediabetes 5.7-6.4\n",
    "#   diabetes >= 6.5\n",
    "ghb[\"diabetes_binary\"] = (ghb[\"a1c\"] >= 5.7).astype(int)\n",
    "\n",
    "selected_columns = [\"SEQN\", \"diabetes_binary\"]\n",
    "ghb = ghb[selected_columns].copy()\n",
    "df = df.merge(ghb, on=\"SEQN\", how=\"inner\")\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fee3f3cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting training for train/val/test...\n",
      "Split sizes (train/val/test): 7907 1695 1695\n",
      "Split sizes (train/val/test): 7907 1695 1695\n"
     ]
    }
   ],
   "source": [
    "# 5 Split Data into Train/Val/Test:\n",
    "print(\"Splitting training for train/val/test...\")\n",
    "\n",
    "X = df.drop(columns=[\"SEQN\", \"diabetes_binary\"])\n",
    "y = df[\"diabetes_binary\"].astype(int)\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.30, random_state=42, stratify=y\n",
    ")\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.50, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "print(\"Split sizes (train/val/test):\", len(X_train), len(X_val), len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4ba26b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation threshold: 0.14045226130653266 F1: 0.27938671209540034\n",
      "Adjusted (recall-boosted) threshold: 0.11236180904522614\n",
      "Test Precision: 0.18363636363636363\n",
      "Test Recall: 0.6352201257861635\n",
      "Test F1: 0.2849083215796897\n",
      "Test PR AUC: 0.22204354827581907\n",
      "Confusion Matrix:\n",
      " [[1087  449]\n",
      " [  58  101]]\n"
     ]
    }
   ],
   "source": [
    "# 6. Train Random Forest\n",
    "# -----------------------------\n",
    "model = RandomForestClassifier(n_estimators=200, class_weight=\"balanced\", random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# choose threshold by maximizing F1 on validation\n",
    "y_val_prob = model.predict_proba(X_val)[:, 1]\n",
    "best_t, best_f1 = 0.0, -1.0\n",
    "for t in np.linspace(0.05, 0.95, 200):\n",
    "    preds = (y_val_prob >= t).astype(int)\n",
    "    score = f1_score(y_val, preds)\n",
    "    if score > best_f1:\n",
    "        best_f1 = score\n",
    "        best_t = t\n",
    "print(\"Best validation threshold:\", best_t, \"F1:\", best_f1)\n",
    "\n",
    "# lower threshold to boost recall\n",
    "adjusted_t = best_t * 0.8\n",
    "print(\"Adjusted (recall-boosted) threshold:\", adjusted_t)\n",
    "\n",
    "y_test_prob = model.predict_proba(X_test)[:, 1]\n",
    "y_test_pred = (y_test_prob >= adjusted_t).astype(int)\n",
    "\n",
    "print(\"Test Precision:\", precision_score(y_test, y_test_pred))\n",
    "print(\"Test Recall:\", recall_score(y_test, y_test_pred))\n",
    "print(\"Test F1:\", f1_score(y_test, y_test_pred))\n",
    "print(\"Test PR AUC:\", average_precision_score(y_test, y_test_prob))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f9eb11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
